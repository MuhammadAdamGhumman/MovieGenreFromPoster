{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "#%matplotlib\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.io as sio\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from scipy.spatial.distance import cdist\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoverTransformation(img1, img2, corr1, corr2):\n",
    "    #Image1 and Image2 are original and transformed input image\n",
    "    #respectively\n",
    "    #MSEPix is mean squared error of pixels of T_image and Image2\n",
    "    #MSECorPts is mean squared error of correspondence points and\n",
    "    #transformed points\n",
    "    #T is recovered transformation\n",
    "    #T_Image is transformed Image\n",
    "    \n",
    "    n = len(corr1)\n",
    "\n",
    "    #plt.imshow(img1)\n",
    "    #p1 = plt.ginput(n, timeout=30)\n",
    "\n",
    "    #plt.imshow(img2)\n",
    "    #p2 = plt.ginput(n, timeout=30)\n",
    "    #plt.close()\n",
    "    \n",
    "    p1 = corr1.copy()\n",
    "    \n",
    "    p2 = corr2.copy()\n",
    "    \n",
    "    one = np.ones([n, 1])\n",
    "\n",
    "    p2 = np.append(p2, one, axis=1)\n",
    "\n",
    "    A = np.zeros([2*n, 6])\n",
    "\n",
    "    B = np.zeros([2*n, 1])\n",
    "    \n",
    "    k = 0\n",
    "    l = 0\n",
    "    for i in range(len(A)):\n",
    "        for j in range(3):\n",
    "            if (l == 0):\n",
    "                A[i][j] = p2[k][j]\n",
    "            else:\n",
    "                A[i][j+3] = p2[k][j]\n",
    "        l = l + 1\n",
    "        if (l == 2):\n",
    "            k = k + 1\n",
    "            l = 0\n",
    "\n",
    "    l = 0\n",
    "    for i in range(n):\n",
    "        B[l] = p1[i][0]\n",
    "        B[l + 1] = p1[i][1]\n",
    "\n",
    "        l = l + 2\n",
    "    \n",
    "    T = (np.linalg.pinv((np.transpose(A)).dot(A))).dot((np.transpose(A)).dot(B))\n",
    "\n",
    "    T = np.reshape(T, (2, 3))\n",
    "    \n",
    "    height, width = img1.shape[:2]\n",
    "    \n",
    "    width = width*2\n",
    "\n",
    "    T_Image = cv2.warpAffine(img2, T, (width, height))\n",
    "    \n",
    "    #plt.imshow(T_Image)\n",
    "    #p3 = plt.ginput(n, timeout=30)\n",
    "    #plt.close()\n",
    "    \n",
    "    #MSEPix = (np.square(img1 - T_Image)).mean()\n",
    "    \n",
    "    #MSECorPts = mean_squared_error(p1, p3) \n",
    "    \n",
    "    return T_Image, T#, MSEPix, MSECorPts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def registerImages(ImageNew, ImageOld, corr1, corr2):\n",
    "    #ImageNew and ImageOld are input images\n",
    "    #registerdImage is the output image\n",
    "    \n",
    "    #img_t, T, MSEPix, MSECorPts = recoverTransformation(ImageNew, ImageOld, 6)\n",
    "    \n",
    "    img_t, T = recoverTransformation(ImageNew, ImageOld, corr1, corr2)\n",
    "    \n",
    "    pers = np.zeros([1, 3])\n",
    "\n",
    "    pers[0][2] = 1\n",
    "    \n",
    "    T = np.append(T, pers, axis = 0)\n",
    "    \n",
    "    mask = np.ones([ImageOld.shape[0], ImageOld.shape[1]])*255\n",
    "    \n",
    "    height, width = ImageNew.shape[:2]\n",
    "    \n",
    "    width = width*2\n",
    "    \n",
    "    img_t = cv2.warpPerspective(ImageOld, T, (width, height))\n",
    "\n",
    "    T_mask = cv2.warpPerspective(mask, T, (width, height))\n",
    "    \n",
    "    registeredImage = ImageNew.copy()\n",
    "    \n",
    "    extra_space = np.zeros(ImageNew.shape)\n",
    "    \n",
    "    registeredImage = np.append(registeredImage, extra_space, axis = 1)\n",
    "    \n",
    "    width_count = 0\n",
    "    \n",
    "    width_check = 0\n",
    "    \n",
    "    for y in range(T_mask.shape[0]):\n",
    "        for x in range(T_mask.shape[1]):\n",
    "            if(T_mask[y][x] == 255):\n",
    "                if(x in np.arange(width/2)):\n",
    "                    width_count = width_count + 1\n",
    "                    width_check = 1\n",
    "        if(width_check == 1):\n",
    "            break\n",
    "        \n",
    "    mul_percent = 1\n",
    "    \n",
    "    mul_percent_change = 1 / width_count\n",
    "    \n",
    "    for y in range(T_mask.shape[0]):\n",
    "        for x in range(T_mask.shape[1]):\n",
    "            if(T_mask[y][x] == 255):\n",
    "                if(x in np.arange(width/2)):\n",
    "                    registeredImage[y][x] = registeredImage[y][x]*mul_percent + img_t[y][x]*(1 - mul_percent)\n",
    "                    mul_percent = mul_percent - mul_percent_change\n",
    "                else:\n",
    "                    registeredImage[y][x] = img_t[y][x]\n",
    "        mul_percent = 1\n",
    "                \n",
    "    #1- get correspondence\n",
    "    #2- recover transformation (use code of part 1)\n",
    "    #3- Transform ImageOld to a new matrix of ImageNew size â€“ use\n",
    "       #cv2.warpAffine() for affine and cv2.warpPerspective() for\n",
    "       #perspective transformation.\n",
    "    #4- Generate a mask of 1's and 0's (1's will represent where pixels\n",
    "       #of ImageOld will land and 0's will represent where pixels of\n",
    "       #ImageNew will land)\n",
    "\n",
    "    return registeredImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stiching(image1, image2, grey):\n",
    "    \n",
    "    set_no = 'set4_'\n",
    "    \n",
    "    height, width = image1.shape[:2]\n",
    "\n",
    "    if(grey == 0):\n",
    "        image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image1_gray = image1\n",
    "\n",
    "    image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    combine = np.append(image1, image2, axis=1)\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    [f1, d1] = sift.detectAndCompute(image1_gray, None)\n",
    "\n",
    "    [f2, d2] = sift.detectAndCompute(image2_gray, None)\n",
    "    \n",
    "    draw =  np.zeros(image1.shape)\n",
    "    \n",
    "    draw = cv2.drawKeypoints(image1, f1, draw)\n",
    "    \n",
    "    cv2.imwrite(set_no + 'featurePoints.jpg', draw)\n",
    "    \n",
    "    f1_mat = np.zeros([4, len(d1)])\n",
    "    \n",
    "    f2_mat = np.zeros([4, len(d2)])\n",
    "    \n",
    "    for i in range(len(d1)):\n",
    "        f1_mat[0][i], f1_mat[1][i] = f1[0].pt\n",
    "        f1_mat[2][i] = f1[0].size\n",
    "        f1_mat[3][i] = f1[0].angle\n",
    "    \n",
    "    for i in range(len(d2)):\n",
    "        f2_mat[0][i], f2_mat[1][i] = f2[0].pt\n",
    "        f2_mat[2][i] = f2[0].size\n",
    "        f2_mat[3][i] = f2[0].angle\n",
    "    \n",
    "    sio.savemat('f1_set4.mat', {\"f1\":f1_mat})\n",
    "    \n",
    "    sio.savemat('f2_set4.mat', {\"f2\":f2_mat})\n",
    "\n",
    "    sio.savemat('d1_set4.mat', {\"d1\":d1})\n",
    "    \n",
    "    sio.savemat('d2_set4.mat', {\"d2\":d2})\n",
    "\n",
    "    eucl_dist = cdist(d1, d2, metric='euclidean')\n",
    "\n",
    "    #print(d1.shape)\n",
    "    #print(d2.shape)\n",
    "    #print(eucl_dist.shape)\n",
    "\n",
    "    eucl_dist_flatten = eucl_dist.flatten()\n",
    "\n",
    "    min_idx = np.argsort(eucl_dist_flatten)\n",
    "    #print(min_idx.shape)\n",
    "\n",
    "    descrip_num = 300\n",
    "\n",
    "    feature1 = np.zeros([descrip_num, 2])\n",
    "\n",
    "    feature2 = np.zeros([descrip_num, 2])\n",
    "\n",
    "    for i in range(descrip_num):\n",
    "\n",
    "            f1_in = (round(f1[int(min_idx[i] / eucl_dist.shape[1])].pt[0]), round(f1[int(min_idx[i] / eucl_dist.shape[1])].pt[1]))\n",
    "            f2_in = (round(f2[int(min_idx[i] % eucl_dist.shape[1])].pt[0] + width), round(f2[int(min_idx[i] % eucl_dist.shape[1])].pt[1]))\n",
    "            f2_in_in = (round(f2[int(min_idx[i] % eucl_dist.shape[1])].pt[0]), round(f2[int(min_idx[i] % eucl_dist.shape[1])].pt[1]))\n",
    "\n",
    "            feature1[i] = f1_in\n",
    "\n",
    "            feature2[i] = f2_in_in\n",
    "\n",
    "            #combine = cv2.circle(combine, f1_in, round(f1[int(min_idx[i] / eucl_dist.shape[1])].size), color = (0, 0, 255), thickness = 2)\n",
    "            #combine = cv2.circle(combine, f2_in, round(f2[int(min_idx[i] % eucl_dist.shape[1])].size), color = (0, 255, 0), thickness = 2) \n",
    "\n",
    "            combine = cv2.circle(combine, f1_in, 10, color = (0, 0, 255), thickness = 2)\n",
    "            combine = cv2.circle(combine, f2_in, 10, color = (0, 255, 0), thickness = 2) \n",
    "\n",
    "\n",
    "            combine = cv2.line(combine, f1_in, f2_in, (0, 255, 255)) \n",
    "\n",
    "    cv2.imwrite(set_no + 'matches.jpg', combine)\n",
    "\n",
    "    corr_num = 3\n",
    "\n",
    "    corres1 = np.zeros([corr_num, 2])\n",
    "\n",
    "    corres2 = np.zeros([corr_num, 2])\n",
    "\n",
    "    numofiter = 1000\n",
    "\n",
    "    idx_check = 0\n",
    "\n",
    "    check = 0\n",
    "\n",
    "    prevhist = 0\n",
    "\n",
    "    height, width = image1.shape[:2]\n",
    "\n",
    "    while(numofiter > 0):\n",
    "\n",
    "        idx1 = random.sample(range(1, len(feature1)), corr_num)\n",
    "\n",
    "        for i in range(corr_num):\n",
    "            corres1[i] = feature1[idx1[i]]\n",
    "            corres2[i] = feature2[idx1[i]]   \n",
    "\n",
    "        img_t, T = recoverTransformation(image1, image2, corres1, corres2)\n",
    "\n",
    "        one = np.ones([len(feature2), 1])\n",
    "\n",
    "        feature2_append = np.append(feature2, one, axis=1)\n",
    "\n",
    "        feature2_append = np.transpose(feature2_append)\n",
    "\n",
    "        key_t = T.dot(feature2_append)\n",
    "\n",
    "        key_t_reshape = np.reshape(key_t, (len(feature2), 2)) \n",
    "\n",
    "        key_t_reshape2 = key_t_reshape.copy()\n",
    "\n",
    "        for i in range(len(key_t_reshape)):\n",
    "            key_t_reshape2[i][0] = key_t[0][i]\n",
    "            key_t_reshape2[i][1] = key_t[1][i]\n",
    "\n",
    "\n",
    "        if(check == 1):\n",
    "            prevhist = hist\n",
    "\n",
    "        hist = 0\n",
    "\n",
    "        thresh = 3\n",
    "\n",
    "        for i in range(len(feature1)):\n",
    "            ECorPts = np.sqrt( (feature1[i][0] - key_t_reshape2[i][0])**2 + (feature1[i][1] - key_t_reshape2[i][1])**2 )\n",
    "            if(ECorPts < thresh):\n",
    "                hist = hist + 1\n",
    "\n",
    "        if (hist > prevhist):\n",
    "            end_key_t = key_t_reshape2.copy()\n",
    "        else:\n",
    "            hist = prevhist\n",
    "\n",
    "        check = 1\n",
    "\n",
    "        numofiter = numofiter - 1\n",
    "\n",
    "\n",
    "    inliers = np.zeros([len(feature1), 1])\n",
    "\n",
    "    feature1_append = np.append(feature1, inliers, axis=1)\n",
    "\n",
    "    feature1_inliers_len = 0\n",
    "\n",
    "    for i in range(len(feature1)):\n",
    "        ECorPts = np.sqrt( (feature1[i][0] - end_key_t[i][0])**2 + (feature1[i][1] - end_key_t[i][1])**2 )\n",
    "        if(ECorPts < thresh):\n",
    "            feature1_append[i][2] = 1 \n",
    "            feature1_inliers_len = feature1_inliers_len + 1\n",
    "\n",
    "    #print(feature1_inliers_len)\n",
    "\n",
    "    final_feature1 = np.zeros([feature1_inliers_len, 2])\n",
    "\n",
    "    final_feature2 = np.zeros([feature1_inliers_len, 2])\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    for i in range(len(feature1)):\n",
    "        if(feature1_append[i][2] == 1):\n",
    "            final_feature1[k] = feature1[i]\n",
    "            final_feature2[k] = feature2[i]\n",
    "\n",
    "            k = k + 1     \n",
    "\n",
    "    image_t = registerImages(image1, image2, final_feature1, final_feature2)\n",
    "\n",
    "    combine = np.append(image1, image2, axis=1)\n",
    "\n",
    "    for i in range(len(final_feature1)):\n",
    "        fe1_in = int(final_feature1[i][0]), int(final_feature1[i][1])\n",
    "        fe2_in = int(final_feature2[i][0] + width), int(final_feature2[i][1])\n",
    "\n",
    "        combine = cv2.circle(combine, fe1_in, 10, color = (0, 0, 255), thickness = 2)\n",
    "        combine = cv2.circle(combine, fe2_in, 10, color = (0, 255, 0), thickness = 2)\n",
    "\n",
    "        combine = cv2.line(combine, fe1_in, fe2_in, (0, 255, 255))\n",
    "        \n",
    "    cv2.imwrite(set_no + 'bestMatches.jpg', combine)\n",
    "        \n",
    "    return image_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_task3_set1 = '/Users/Adam/Desktop/Assignment 5/task3/Set1/'\n",
    "\n",
    "path_task3_set2 = '/Users/Adam/Desktop/Assignment 5/task3/Set2/'\n",
    "\n",
    "path_task3_set3 = '/Users/Adam/Desktop/Assignment 5/task3/Set3/'\n",
    "\n",
    "path_task3_set4 = '/Users/Adam/Desktop/Assignment 5/task3/Set4/'\n",
    "\n",
    "build1 = cv2.imread(path_task3_set4 + 'image1.jpg')\n",
    "\n",
    "build2 = cv2.imread(path_task3_set4 + 'image2.jpg')\n",
    "\n",
    "#build1 = cv2.imread(path_task3_set3 + 'image3.jpg')\n",
    "\n",
    "#build2 = cv2.imread(path_task3_set3 + 'image4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "build_t = stiching(build1.copy(), build2.copy(), 0)\n",
    "\n",
    "#build_t = stiching(build_t.copy(), build3.copy(), 1)\n",
    "\n",
    "cv2.imwrite('set3_panorama.jpg', build_t)\n",
    "\n",
    "print(\"done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cv_course]",
   "language": "python",
   "name": "conda-env-cv_course-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt \n",
    "import glob\n",
    "import os\n",
    "#import keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense, Dropout, Flatten\n",
    "#from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       imdbId                           Imdb Link  \\\n",
      "0      114709  http://www.imdb.com/title/tt114709   \n",
      "1      113497  http://www.imdb.com/title/tt113497   \n",
      "2      113228  http://www.imdb.com/title/tt113228   \n",
      "3      114885  http://www.imdb.com/title/tt114885   \n",
      "4      113041  http://www.imdb.com/title/tt113041   \n",
      "...       ...                                 ...   \n",
      "40103   83168   http://www.imdb.com/title/tt83168   \n",
      "40104   82875   http://www.imdb.com/title/tt82875   \n",
      "40105  815258  http://www.imdb.com/title/tt815258   \n",
      "40106   79142   http://www.imdb.com/title/tt79142   \n",
      "40107   70710   http://www.imdb.com/title/tt70710   \n",
      "\n",
      "                                    Title  IMDB Score  \\\n",
      "0                        Toy Story (1995)         8.3   \n",
      "1                          Jumanji (1995)         6.9   \n",
      "2                 Grumpier Old Men (1995)         6.6   \n",
      "3                Waiting to Exhale (1995)         5.7   \n",
      "4      Father of the Bride Part II (1995)         5.9   \n",
      "...                                   ...         ...   \n",
      "40103               Tanya's Island (1980)         4.3   \n",
      "40104               Pacific Banana (1981)         4.7   \n",
      "40105  Werewolf in a Womens Prison (2006)         4.5   \n",
      "40106              Xiao zi ming da (1979)         6.5   \n",
      "40107                     Snatched (1973)         6.5   \n",
      "\n",
      "                            Genre  \\\n",
      "0      Animation|Adventure|Comedy   \n",
      "1         Action|Adventure|Family   \n",
      "2                  Comedy|Romance   \n",
      "3            Comedy|Drama|Romance   \n",
      "4           Comedy|Family|Romance   \n",
      "...                           ...   \n",
      "40103                       Drama   \n",
      "40104                      Comedy   \n",
      "40105                      Horror   \n",
      "40106               Action|Comedy   \n",
      "40107        Crime|Drama|Thriller   \n",
      "\n",
      "                                                  Poster  \n",
      "0      https://images-na.ssl-images-amazon.com/images...  \n",
      "1      https://images-na.ssl-images-amazon.com/images...  \n",
      "2      https://images-na.ssl-images-amazon.com/images...  \n",
      "3      https://images-na.ssl-images-amazon.com/images...  \n",
      "4      https://images-na.ssl-images-amazon.com/images...  \n",
      "...                                                  ...  \n",
      "40103  https://images-na.ssl-images-amazon.com/images...  \n",
      "40104  https://images-na.ssl-images-amazon.com/images...  \n",
      "40105  https://images-na.ssl-images-amazon.com/images...  \n",
      "40106  https://images-na.ssl-images-amazon.com/images...  \n",
      "40107                                                NaN  \n",
      "\n",
      "[40108 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "poster_dest = \"/Users/Adam/Desktop/Project/Movies/posters/\"\n",
    "train = \"/Users/Adam/Desktop/Project/Movies/image-classification/dataset/train/\"\n",
    "test = \"/Users/Adam/Desktop/Project/Movies/image-classification/dataset/test/\"\n",
    "df_movietotal = pd.read_csv(\"MovieGenre.csv\", encoding='latin1')\n",
    "print(df_movietotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movietotal_copy = df_movietotal.copy()\n",
    "df_movietotal_copy = df_movietotal_copy.dropna(axis=0)\n",
    "df_movietotal_copy = df_movietotal_copy.reset_index(drop=True)\n",
    "#for i in range(len(df_movietotal_copy)):\n",
    "    #try:\n",
    "        #if (cv2.imread(train + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg') == None) and (cv2.imread(test + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg') == None):\n",
    "            #df_movietotal_copy = df_movietotal_copy[df_movietotal_copy.imdbId != df_movietotal_copy[\"imdbId\"][i]]\n",
    "    #except:\n",
    "        #continue\n",
    "df_movietotal_copy = df_movietotal_copy.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112541\n",
      "113044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "j = 999\n",
    "test_none_img = 0\n",
    "train_none_img = 0\n",
    "ids = []\n",
    "for i in range(0, j):\n",
    "    try:\n",
    "        if (i < 750):\n",
    "            img = cv2.imread(poster_dest + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg')\n",
    "            cv2.imwrite(train + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg', img)\n",
    "            ids.append(df_movietotal_copy[\"imdbId\"][i])\n",
    "        else:\n",
    "            img = cv2.imread(poster_dest + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg')\n",
    "            cv2.imwrite(test + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg', img)\n",
    "            ids.append(df_movietotal_copy[\"imdbId\"][i])\n",
    "    except:\n",
    "        print(df_movietotal_copy[\"imdbId\"][i])\n",
    "        if (i < 750):\n",
    "            train_none_img = train_none_img + 1\n",
    "        else:\n",
    "            test_none_img = test_none_img + 1\n",
    "\n",
    "for i in range(j, j + test_none_img + 1):\n",
    "    img = cv2.imread(poster_dest + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg')\n",
    "    cv2.imwrite(test + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg', img)\n",
    "    ids.append(df_movietotal_copy[\"imdbId\"][i])\n",
    "    \n",
    "j = j + test_none_img\n",
    "    \n",
    "for i in range(j, j + train_none_img):\n",
    "    img = cv2.imread(poster_dest + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg')\n",
    "    cv2.imwrite(train + str(df_movietotal_copy[\"imdbId\"][i]) + '.jpg', img)\n",
    "    ids.append(df_movietotal_copy[\"imdbId\"][i])\n",
    "    \n",
    "np.array(ids)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39246"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_movietotal_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_per_movie = []\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    genre_per_movie.append(df_movietotal_copy[ids[i] == df_movietotal_copy[\"imdbId\"]][\"Genre\"].apply(lambda x: str(x).split(\"|\")))   \n",
    "    \n",
    "genre_per_movie2 = np.array(genre_per_movie[0])\n",
    "\n",
    "for i in range(len(ids) - 1):\n",
    "    genre_per_movie2 = np.append(genre_per_movie2, genre_per_movie[i + 1])\n",
    "\n",
    "    \n",
    "single_genre = []\n",
    "for i in range(len(genre_per_movie2)):\n",
    "    single_genre.append(genre_per_movie2[i][0])\n",
    "\n",
    "single_genre = np.array(single_genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Number of Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action  =  140\n",
      "Adventure  =  51\n",
      "Animation  =  36\n",
      "Biography  =  40\n",
      "Comedy  =  330\n",
      "Crime  =  81\n",
      "Documentary  =  28\n",
      "Drama  =  239\n",
      "Family  =  9\n",
      "Fantasy  =  6\n",
      "Film-Noir  =  1\n",
      "Horror  =  16\n",
      "Musical  =  1\n",
      "Mystery  =  6\n",
      "Romance  =  8\n",
      "Sci-Fi  =  3\n",
      "Short  =  1\n",
      "Thriller  =  3\n",
      "Western  =  1\n"
     ]
    }
   ],
   "source": [
    "flat_list = []\n",
    "\n",
    "def flatten_list(thelist):\n",
    "    for sublist in thelist:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    np.array(flat_list)\n",
    "    return flat_list\n",
    "        \n",
    "#flat_list = flatten_list(genre_per_movie)\n",
    "\n",
    "unique, counts = np.unique(single_genre, return_counts=True)\n",
    "class_names = dict(zip(unique, counts))\n",
    "\n",
    "for key, value in class_names.items():\n",
    "    print (key, \" = \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset\"\n",
    "\n",
    "for x in class_names:\n",
    "    # create a folder for that class\n",
    "    try:\n",
    "        os.makedirs(train_dir + \"\\\\train\\\\\" + x)\n",
    "        os.makedirs(train_dir + \"\\\\test\\\\\" + x)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # get the current path\n",
    "    cur_path = train_dir + \"\\\\train\\\\\" + x + \"\\\\\"\n",
    "    \n",
    "    cur_path2 = train_dir + \"\\\\test\\\\\" + x + \"\\\\\"\n",
    "    \n",
    "    for i in range(len(single_genre)):\n",
    "        \n",
    "        if (x == single_genre[i]):\n",
    "            original_path   = train + str(ids[i]) + \".jpg\"\n",
    "            image_file_name = str(ids[i]) + \".jpg\"\n",
    "            try:\n",
    "                os.rename(original_path, cur_path + image_file_name)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    for i in range(len(single_genre)):\n",
    "        \n",
    "        if (x == single_genre[i]):\n",
    "            original_path   = test + str(ids[i]) + \".jpg\"\n",
    "            image_file_name = str(ids[i]) + \".jpg\"\n",
    "            try:\n",
    "                os.rename(original_path, cur_path2 + image_file_name)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_histogram(image, mask=None):\n",
    "    # convert the image to HSV color-space\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # compute the color histogram\n",
    "    hist  = cv2.calcHist([image], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    # normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # return the histogram\n",
    "    \n",
    "    hist = hist.flatten()\n",
    "    \n",
    "    return hist[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Features for Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "new_ids = []\n",
    "\n",
    "check = 0\n",
    "\n",
    "for key, value in class_names.items():\n",
    "    \n",
    "    current_label = key\n",
    "    \n",
    "    for i in range(len(single_genre)):\n",
    "        \n",
    "        if (single_genre[i] == key):\n",
    "            \n",
    "            \n",
    "            img = cv2.imread(train + single_genre[i] + \"/\" + str(ids[i]) + '.jpg')\n",
    "            \n",
    "            try:\n",
    "                f = fd_histogram(img)\n",
    "            except:\n",
    "                check = 1\n",
    "            \n",
    "            if (check != 1):\n",
    "                features.append(f)\n",
    "                labels.append(current_label)\n",
    "                new_ids.append(ids[i])\n",
    "            \n",
    "            check = 0\n",
    "            \n",
    "features = np.array(features)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "new_ids = np.array(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(features)\n",
    "# print(len(features))\n",
    "# print()\n",
    "# print()\n",
    "# print(labels)\n",
    "# print(len(labels))\n",
    "# print()\n",
    "# print()\n",
    "# print(new_ids)\n",
    "# print(len(new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.shape =  (100, 17)\n",
      "w =  [[ 0.52436946  0.62956725 -0.01443494 ...  0.0019406   0.0008414\n",
      "  -0.00905399]\n",
      " [ 0.04138855  0.12818674  0.05561229 ...  0.01209308  0.00726169\n",
      "  -0.02966869]\n",
      " [ 0.01309848 -0.0116918  -0.01935337 ...  0.08827577  0.09138381\n",
      "  -0.1143353 ]\n",
      " ...\n",
      " [ 0.00382174  0.00404397  0.00804125 ...  0.00738276  0.01461278\n",
      "   0.00417114]\n",
      " [ 0.00097563  0.00090231 -0.00082742 ... -0.00445315 -0.00070092\n",
      "   0.00203848]\n",
      " [ 0.0026087   0.00436177  0.00170647 ... -0.00511064 -0.0104523\n",
      "  -0.00239411]]\n"
     ]
    }
   ],
   "source": [
    "def mda(new_ids, features, labels, class_names):\n",
    "\n",
    "    means = dict()\n",
    "    for c in class_names:\n",
    "        if c != 'Western' and c != 'Film-Noir':\n",
    "            means[c] = features[np.where(labels == c)].mean(axis = 0)\n",
    "            \n",
    "    overall_mean = features.mean(axis = 0)\n",
    "\n",
    "    S_B = np.zeros((features.shape[1], features.shape[1]))\n",
    "    for c in means.keys(): \n",
    "        if c != 'Western' and c != 'Film-Noir':\n",
    "            #print(np.outer((means[c] - overall_mean), (means[c] - overall_mean))) \n",
    "            S_B += np.multiply((features[np.where(labels == c)].shape[0]*features[np.where(labels == c)].shape[1]), ((means[c] - overall_mean)*(means[c] - overall_mean).T))\n",
    "    \n",
    "    S_W = np.zeros(S_B.shape)\n",
    "    for c in class_names: \n",
    "        if c != 'Western' and c != 'Film-Noir':\n",
    "            for i in range(len(features[np.where(labels == c)])):\n",
    "                S_W += (features[np.where(labels == c)][i] - means[c])*((features[np.where(labels == c)][i] - means[c]).T)\n",
    "\n",
    "    \n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.pinv(S_W).dot(S_B))\n",
    "    \n",
    "    eiglist = [(eigvals[i], eigvecs[:, i]) for i in range(len(eigvals))] \n",
    "    \n",
    "    \n",
    "    eiglist = sorted(eiglist, key = lambda x : x[0], reverse = True)\n",
    "    \n",
    "    w = np.hstack((eiglist[0][1].reshape(100,1), eiglist[1][1].reshape(100,1), eiglist[2][1].reshape(100,1), eiglist[3][1].reshape(100,1), eiglist[4][1].reshape(100,1), eiglist[5][1].reshape(100,1), eiglist[6][1].reshape(100,1), eiglist[7][1].reshape(100,1), eiglist[8][1].reshape(100,1), eiglist[9][1].reshape(100,1), eiglist[11][1].reshape(100,1), eiglist[12][1].reshape(100,1), eiglist[13][1].reshape(100,1), eiglist[14][1].reshape(100,1), eiglist[15][1].reshape(100,1), eiglist[16][1].reshape(100,1), eiglist[17][1].reshape(100,1)) ).real\n",
    "                        \n",
    "    return w, means\n",
    "\n",
    "\n",
    "w, mean= mda(new_ids, features, labels, class_names)\n",
    "\n",
    "\n",
    "print(\"w.shape = \", w.shape)\n",
    "print(\"w = \", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    \n",
    "    clf = LinearSVC()\n",
    "\n",
    "    clf.fit(train_image_feats, train_labels)\n",
    "    \n",
    "    predicted_categories = clf.predict(test_image_feats)\n",
    "    \n",
    "    return predicted_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing Features for Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = []\n",
    "\n",
    "test_labels = []\n",
    "\n",
    "test_new_ids = []\n",
    "\n",
    "check = 0\n",
    "for key, value in class_names.items():\n",
    "    \n",
    "    current_label = key\n",
    "    \n",
    "    for i in range(len(single_genre)):\n",
    "        \n",
    "        if (single_genre[i] == key):\n",
    "\n",
    "            img = cv2.imread(test + single_genre[i] + \"/\" + str(ids[i]) + '.jpg')\n",
    "            \n",
    "            try:\n",
    "                f = fd_histogram(img)\n",
    "            except:\n",
    "                check = 1\n",
    "            \n",
    "            if (check != 1):\n",
    "                test_features.append(f)\n",
    "                test_labels.append(current_label)\n",
    "                test_new_ids.append(ids[i])\n",
    "            \n",
    "            check = 0\n",
    "            \n",
    "test_features = np.array(test_features)\n",
    "\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "test_new_ids = np.array(test_new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_features)\n",
    "# print(len(test_features))\n",
    "# print()\n",
    "# print()\n",
    "# print(test_labels)\n",
    "# print(len(test_labels))\n",
    "# print()\n",
    "# print()\n",
    "# print(test_new_ids)\n",
    "# print(len(test_new_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_mda = np.array(features.dot(w))\n",
    "\n",
    "features_test_mda = np.array(test_features.dot(w))\n",
    "\n",
    "perd = svm_classify(features_train_mda, labels, features_test_mda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(perd)\n",
    "#print(len(perd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.65338645418327 %\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for i in range(len(test_labels)):\n",
    "    if (test_labels[i] == perd[i]):\n",
    "        accuracy = accuracy + 1\n",
    "        \n",
    "accuracy = accuracy / len(test_labels)\n",
    "\n",
    "print(accuracy*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
